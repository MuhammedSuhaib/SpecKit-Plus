"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[451],{4982:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>s,default:()=>u,frontMatter:()=>r,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"module-04-vision-language-action/intro","title":"CHAPTER 4","description":"Vision-Language-Action (VLA) - Overview","source":"@site/docs/module-04-vision-language-action/intro.mdx","sourceDirName":"module-04-vision-language-action","slug":"/module-04-vision-language-action/intro","permalink":"/dockathon/docs/module-04-vision-language-action/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-04-vision-language-action/intro.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 06: Navigation - Nav2 and SLAM","permalink":"/dockathon/docs/module-03-ai-robot-brain/chapter-06-navigation"},"next":{"title":"Chapter 7: Whisper Voice Integration - Voice-to-Action Logic","permalink":"/dockathon/docs/module-04-vision-language-action/chapter-07-whisper"}}');var i=o(2714),a=o(8885);const r={sidebar_position:1},s="CHAPTER 4",c={},l=[{value:"Vision-Language-Action (VLA) - Overview",id:"vision-language-action-vla---overview",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",p:"p",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"chapter-4",children:"CHAPTER 4"})}),"\n",(0,i.jsx)(n.h2,{id:"vision-language-action-vla---overview",children:"Vision-Language-Action (VLA) - Overview"}),"\n",(0,i.jsx)(n.p,{children:"Vision-Language-Action (VLA) systems represent the convergence of perception, cognition, and action in embodied AI. This module explores how visual processing, language understanding, and robotic control can be integrated to create intelligent agents capable of interacting naturally with their environment."})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8885:(e,n,o)=>{o.d(n,{R:()=>r,x:()=>s});var t=o(9378);const i={},a=t.createContext(i);function r(e){const n=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),t.createElement(a.Provider,{value:n},e.children)}}}]);