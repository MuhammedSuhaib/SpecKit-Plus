"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[252],{1559:(e,n,o)=>{o.r(n),o.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"module-03-ai-robot-brain/intro","title":"Module 3: AI Robot Brain - Perception Overview","description":"Introduction to Perception in AI Robotics","source":"@site/docs/module-03-ai-robot-brain/intro.md","sourceDirName":"module-03-ai-robot-brain","slug":"/module-03-ai-robot-brain/intro","permalink":"/dockathon/docs/module-03-ai-robot-brain/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-03-ai-robot-brain/intro.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Why we simulate","permalink":"/dockathon/docs/module-02-digital-twin/intro"},"next":{"title":"Module 4: Vision-Language-Action (VLA) - Overview","permalink":"/dockathon/docs/module-04-vision-language-action/intro"}}');var t=o(2714),r=o(8885);const s={sidebar_position:1},a="Module 3: AI Robot Brain - Perception Overview",c={},l=[{value:"Introduction to Perception in AI Robotics",id:"introduction-to-perception-in-ai-robotics",level:2},{value:"Key Components of Robot Perception",id:"key-components-of-robot-perception",level:2},{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Module Structure",id:"module-structure",level:2}];function d(e){const n={h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"module-3-ai-robot-brain---perception-overview",children:"Module 3: AI Robot Brain - Perception Overview"})}),"\n",(0,t.jsx)(n.h2,{id:"introduction-to-perception-in-ai-robotics",children:"Introduction to Perception in AI Robotics"}),"\n",(0,t.jsx)(n.p,{children:"Perception forms the foundation of intelligent robotic behavior, enabling robots to interpret and understand their environment. In AI robotics, perception systems act as the robot's sensory apparatus, processing real-world data to make informed decisions and navigate complex scenarios."}),"\n",(0,t.jsx)(n.h2,{id:"key-components-of-robot-perception",children:"Key Components of Robot Perception"}),"\n",(0,t.jsx)(n.p,{children:"This module explores the critical aspects of robotic perception:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Computer Vision"}),": Processing visual information to identify objects, understand spatial relationships, and navigate environments"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Sensor Integration"}),": Combining multiple sensor inputs to create a comprehensive understanding of the environment"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Depth Perception"}),": Understanding three-dimensional space and distances for safe navigation"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real-time Processing"}),": Handling sensor data streams in real-time for responsive behavior"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,t.jsx)(n.p,{children:"By the end of this module, you will understand:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"How robots process visual information using computer vision techniques"}),"\n",(0,t.jsx)(n.li,{children:"The role of depth cameras in spatial perception"}),"\n",(0,t.jsx)(n.li,{children:"Navigation systems that enable autonomous movement"}),"\n",(0,t.jsx)(n.li,{children:"The integration of perception with decision-making systems"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"module-structure",children:"Module Structure"}),"\n",(0,t.jsx)(n.p,{children:"This module is organized into:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Chapter 05: Computer Vision (featuring YOLO and Depth cameras)"}),"\n",(0,t.jsx)(n.li,{children:"Chapter 06: Navigation (covering Nav2 and SLAM)"}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Perception is the first step in the classic perception-action cycle, where robots must first understand their environment before executing appropriate actions."})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8885:(e,n,o)=>{o.d(n,{R:()=>s,x:()=>a});var i=o(9378);const t={},r=i.createContext(t);function s(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);