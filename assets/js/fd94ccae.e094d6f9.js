"use strict";(globalThis.webpackChunkfrontend=globalThis.webpackChunkfrontend||[]).push([[198],{164:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>d,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"module-03-ai-robot-brain/intro","title":"intro","description":"AI Robot Brain - Perception Overview","source":"@site/docs/module-03-ai-robot-brain/intro.mdx","sourceDirName":"module-03-ai-robot-brain","slug":"/module-03-ai-robot-brain/intro","permalink":"/dockathon/docs/module-03-ai-robot-brain/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-03-ai-robot-brain/intro.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Intro to NVIDIA Omniverse & USD","permalink":"/dockathon/docs/module-02-digital-twin/chapter-04-isaac-sim"},"next":{"title":"Chapter 05: Computer Vision - YOLO and Depth Cameras","permalink":"/dockathon/docs/module-03-ai-robot-brain/chapter-05-computer-vision"}}');var i=n(2714),r=n(8885),a=n(4309);const s={sidebar_position:1},d="CHAPTER 3",c={},l=[{value:"AI Robot Brain - Perception Overview",id:"ai-robot-brain---perception-overview",level:2}];function p(e){const t={h1:"h1",h2:"h2",header:"header",p:"p",...(0,r.R)(),...e.components};return(0,i.jsxs)("div",{style:{position:"relative",overflow:"hidden",minHeight:"300px",marginBottom:"2rem"},children:[(0,i.jsx)(a.A,{}),(0,i.jsxs)("div",{style:{position:"relative",zIndex:1,color:"var(--ifm-color-emphasis-900)",padding:"2rem"},children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"chapter-3",children:"CHAPTER 3"})}),(0,i.jsx)(t.h2,{id:"ai-robot-brain---perception-overview",children:"AI Robot Brain - Perception Overview"}),(0,i.jsx)(t.p,{children:"Perception forms the foundation of intelligent robotic behavior, enabling robots to interpret and understand their environment. In AI robotics, perception systems act as the robot's sensory apparatus, processing real-world data to make informed decisions and navigate complex scenarios."})]})]})}function h(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},4309:(e,t,n)=>{n.d(t,{A:()=>r});var o=n(9378),i=n(2714);function r({opacity:e=.12,fullScreen:t=!0}){const n=(0,o.useRef)(null);(0,o.useEffect)(()=>{const o=n.current,i=o.getContext("2d");(()=>{const n=o.parentElement;let r,a;if(t)r=window.innerWidth,a=window.innerHeight;else{const e=n.getBoundingClientRect();r=e.width,a=e.height}o.width=r,o.height=a;const s=Math.floor(r/14)+1,d=Array(s).fill(0),c=()=>{i.fillStyle=`rgba(0,0,0,${e})`,i.fillRect(0,0,r,a),i.fillStyle="#00FF41",i.font="14px monospace";for(let e=0;e<d.length;e++){const t=String.fromCharCode(12448+96*Math.random());i.fillText(t,14*e,14*d[e]),14*d[e]>a&&Math.random()>.975&&(d[e]=0),d[e]++}};c();const l=setInterval(c,45);if(t){const e=()=>{o.width=window.innerWidth,o.height=window.innerHeight};return window.addEventListener("resize",e),()=>{clearInterval(l),window.removeEventListener("resize",e)}}})()},[e,t]);const r=t?{position:"fixed",inset:0,zIndex:0,pointerEvents:"none"}:{position:"absolute",top:0,left:0,width:"100%",height:"100%",zIndex:0,pointerEvents:"none"};return(0,i.jsx)("canvas",{ref:n,style:r})}},8885:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>s});var o=n(9378);const i={},r=o.createContext(i);function a(e){const t=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function s(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),o.createElement(r.Provider,{value:t},e.children)}}}]);